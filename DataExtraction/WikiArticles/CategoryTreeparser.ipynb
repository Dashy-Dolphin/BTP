{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# URL of the page to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/Category:Machine_learning'\n",
    "\n",
    "base = \"https://en.wikipedia.org\"\n",
    "fp = open('output_links_ai.txt', 'w')\n",
    "fp2 = open('debug.txt', 'w')\n",
    "\n",
    "\n",
    "def print_links():\n",
    "    \n",
    "\n",
    "    fp.flush()\n",
    "\n",
    "\n",
    "def extractor(url,treelen=0):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    hrefs=[]\n",
    "\n",
    "    category = url.split('/')[-1]  \n",
    "    # fp2.write(category + \" \" + str(treelen)+ '\\n')\n",
    "    # fp2.flush()\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the div with id 'mw-pages'\n",
    "    mw_pages_div = soup.find('div', id='mw-pages')\n",
    "\n",
    "    mw_subc_div = soup.find('div', id='mw-subcategories')\n",
    "\n",
    "\n",
    "\n",
    "    if mw_subc_div is not None:\n",
    "        rec_links = mw_subc_div.find_all('a')\n",
    "        rec_hrefs = [rec_link.get('href') for rec_link in rec_links]\n",
    "        \n",
    "        for rec_href in rec_hrefs:\n",
    "            if rec_href is not None:\n",
    "                rec_url = base + rec_href\n",
    "                extractor(rec_url,treelen+1)\n",
    "\n",
    "    if mw_pages_div is not None:\n",
    "        # Find all the anchor tags within mw-pages div\n",
    "        links = mw_pages_div.find_all('a')\n",
    "\n",
    "        # Extract href attributes\n",
    "        for link in links:\n",
    "            hrefs.append(link.get('href'))\n",
    "\n",
    "\n",
    "        hrefs = list(set(hrefs))\n",
    "        hrefs = '\\n'.join(hrefs)\n",
    "\n",
    "        fp.write(hrefs)\n",
    "        fp.flush()\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://en.wikipedia.org/wiki/Category:Artificial_intelligence\"\n",
    "url3 = \"https://en.wikipedia.org/wiki/Category:Data_mining\"\n",
    "url4 = \"https://en.wikipedia.org/w/index.php?title=Category:Machine_learning&pagefrom=Soderholm%2C+Lynda%0ALynda+Soderholm#mw-pages\"\n",
    "\n",
    "extractor(url2)\n",
    "\n",
    "\n",
    "fp.close()\n",
    "fp2.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
